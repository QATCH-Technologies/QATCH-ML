# -*- coding: utf-8 -*-
"""Determine_Start_of_main_QuickGraph.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1I16s5HMSgn98GX8jIMedg9fcpcngDZxL

Create noisy data and randomly add a noisy sin function after some offset.  Train the network to identify the offset.  Last time we did classification (true/false).  This is regression (returns a float).
"""

# Commented out IPython magic to ensure Python compatibility.
# %autosave 60

# # Check libcudnn8 version
# !apt-cache policy libcudnn8

# # Install latest version
# !apt install --allow-change-held-packages libcudnn8=8.4.1.50-1+cuda11.6

# # Export env variables
# !export PATH=/usr/local/cuda-11.4/bin${PATH:+:${PATH}}
# !export LD_LIBRARY_PATH=/usr/local/cuda-11.4/lib64:$LD_LIBRARY_PATH
# !export LD_LIBRARY_PATH=/usr/local/cuda-11.4/include:$LD_LIBRARY_PATH
# !export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:/usr/local/cuda/extras/CUPTI/lib64

# # Install tensorflow
# !pip install tflite-model-maker==0.4.0
# !pip uninstall -y tensorflow && pip install -q tensorflow==2.9.1
# !pip install pycocotools==2.0.4
# !pip install opencv-python-headless==4.6.0.66

# Commented out IPython magic to ensure Python compatibility.
import matplotlib.pyplot as plt
# %matplotlib inline
plt.ion()
import numpy as np
import csv

import pandas as pd
import tensorflow as tf
from tensorflow.keras import layers
import sklearn
import sklearn.model_selection
np.set_printoptions(precision=3, suppress=True) # Make numpy values easier to read.
from random import random

HOW_MANY_DATA_POINTS_PER_ROW = 1000
MAX_AMPLITUDE = 10
MAX_NOISE = .25
MAX_VALUE = 100
x = np.linspace(0, MAX_VALUE, HOW_MANY_DATA_POINTS_PER_ROW)

def returnFakeRow():
  noise = np.random.normal(0,MAX_NOISE,x.shape)+25
  randSin = (random() + 0.2) * 0.1 #allows for different wave lengths
  offset1 = int(random() * 350) + 100 #random range from 100 to 450
  offset2 = int(random() * 200) + 750 #random range from 750 to 950
  noise[offset1:offset2] = [xt+(2*MAX_AMPLITUDE)+MAX_AMPLITUDE*np.sin(ixt * randSin) for ixt, xt in enumerate(noise[offset1:offset2])] #[xt+np.cos(xt) for xt in sin[offset:]]
  noise[offset2:] = [xt+(4*MAX_AMPLITUDE) for ixt, xt in enumerate(noise[offset2:])]

  return noise, randSin, offset1, offset2

print(returnFakeRow())

#show a random sample
row = returnFakeRow()
print("Rand Sin wavelength: " + str(round(row[1], 1)))
print("Noisy Sin starts at: " + str(row[2]))
print("Noisy Sin ends at: " + str(round(row[3], 1)))
plt.plot(x, row[0], '-')

#reusing earlier code so ignore variable names... obviously there are only good rows

CSV_PATH = 'content/dummyData.csv'
HOW_MANY_ROWS_FOR_EACH_GOOD_AND_BAD = 10000
#create 1,000 samples.  500 good, 500 bag and save to dummyData.csv
def createCSV():
  f = open(CSV_PATH, 'w')
  writer = csv.writer(f)

  #write header row
  row = np.insert(x,0,-3) #reserving header -3 for the stop
  row = np.insert(row,0,-2) #reserving header -2 for the start
  row = np.insert(row,0,-1) #reserving header -1 for the wavelength
  writer.writerow(row)

  #Write Good rows
  for i in range(0,HOW_MANY_ROWS_FOR_EACH_GOOD_AND_BAD):
    row = returnFakeRow()
    label1 = row[1] #1 = wavelength
    label2 = row[2] #2 = start
    label3 = row[3] #3 = stop
    row = np.insert(row[0],0,label3) #add label3 as third column
    row = np.insert(row,0,label2) #add label1 as second column
    row = np.insert(row,0,label1) #add label1 as first column
    writer.writerow(row)

  f.close()


createCSV()

"""Import CSV data"""

csv_import = pd.read_csv(CSV_PATH)

#print first 5 rows
csv_import.head()

csv_features = csv_import.copy()
csv_labels1 = csv_features.pop('-1.0') #first column is good (1.0) vs bad (0.0).  Therefore label
csv_labels2 = csv_features.pop('-2.0') #first column is good (1.0) vs bad (0.0).  Therefore label
csv_labels3 = csv_features.pop('-3.0') #first column is good (1.0) vs bad (0.0).  Therefore label

#format as numpy
csv_features = np.array(csv_features)
csv_labels1 = np.array(csv_labels1).astype(float)
csv_labels2 = np.array(csv_labels2).astype(float)
csv_labels3 = np.array(csv_labels3).astype(float)

#print how many rows per offset we've imported
(unique, counts) = np.unique(np.round(csv_labels1, 1), return_counts=True)
frequencies = np.asarray((unique, counts)).T

print(frequencies)

#print how many rows per offset we've imported
(unique, counts) = np.unique(np.round(csv_labels2, 1), return_counts=True)
frequencies = np.asarray((unique, counts)).T

print(frequencies)

#print how many rows per offset we've imported
(unique, counts) = np.unique(np.round(csv_labels3, 1), return_counts=True)
frequencies = np.asarray((unique, counts)).T

print(frequencies)

"""Time for ML training"""

#normalize for optimal train
normalize = layers.Normalization()
normalize.adapt(csv_features)

if False:
  csv_model = tf.keras.Sequential(
    [
        layers.Input(shape=(1000,1)),
        layers.Conv1D(
            filters=32, kernel_size=7, padding="same", strides=2, activation="relu"
        ),
        layers.Flatten(),
        layers.Dense(1)
    ]
  )
  #BinaryCrossentropy / MeanSquaredError / tf.keras.losses.BinaryCrossentropy()
  csv_model.compile(loss = 'mean_absolute_error', #from_logits=True
                        optimizer = tf.optimizers.Adam(learning_rate=0.003))
else:
   # Define model layers.
    input_layer0 = layers.Input(shape=(HOW_MANY_DATA_POINTS_PER_ROW,))
    first_layer0 = normalize(input_layer0)

    NUM_DIMS = 1028
    DROPOUTS = 0.2

    #second_layer0 = layers.Dense(NUM_DIMS, activation='relu')(first_layer0)
    #third_layer0 = layers.Dropout(DROPOUTS)(second_layer0)
    #fourth_layer0 = layers.Dense(NUM_DIMS/2, activation='relu')(third_layer0)

    second_layer1 = layers.Dense(NUM_DIMS, activation='relu')(first_layer0)
    third_layer1 = layers.Dropout(DROPOUTS)(second_layer1)
    fourth_layer1 = layers.Dense(NUM_DIMS/2, activation='relu')(third_layer1)
    # Y1 output will be fed from the fourth layer
    y1_output = layers.Dense(1, name='wavelength')(fourth_layer1)

    second_layer2 = layers.Dense(NUM_DIMS, activation='relu')(first_layer0)
    third_layer2 = layers.Dropout(DROPOUTS)(second_layer2)
    fourth_layer2 = layers.Dense(NUM_DIMS)(third_layer2)
    # Y2 output will be fed from the fourth layer
    y2_output = layers.Dense(1, name='start')(fourth_layer2)

    second_layer3 = layers.Dense(NUM_DIMS, activation='relu')(first_layer0)
    third_layer3 = layers.Dropout(DROPOUTS)(second_layer3)
    fourth_layer3 = layers.Dense(NUM_DIMS)(third_layer3)
    # Y3 output will be fed from the fourth layer
    y3_output = layers.Dense(1, name='stop')(fourth_layer3)

    # Define the model with the input layer
    # and a list of output layers
    csv_model = tf.keras.Model(inputs=input_layer0,outputs=[y1_output, y2_output, y3_output])

    # Specify the optimizer, and compile the model with loss functions for both outputs
    optimizer = tf.optimizers.Adam(learning_rate=0.003)

    csv_model.compile(optimizer=optimizer,
                      loss={'wavelength': tf.keras.losses.MeanAbsoluteError(),
                            'start': tf.keras.losses.MeanAbsoluteError(),
                            'stop': tf.keras.losses.MeanAbsoluteError()},
                      metrics={'wavelength': tf.keras.metrics.MeanAbsoluteError(),
                               'start': tf.keras.metrics.MeanAbsoluteError(),
                               'stop': tf.keras.metrics.MeanAbsoluteError()})
    '''
    csv_model.compile(optimizer=optimizer,
                      loss={'wavelength': 'mean_absolute_error',
                            'start': 'mean_absolute_error',
                            'stop': 'mean_absolute_error'},
                      metrics={'wavelength':tf.keras.metrics.MeanAbsoluteError(),
                            'start':tf.keras.metrics.MeanAbsoluteError(),
                            'stop':tf.keras.metrics.MeanAbsoluteError()})
    '''
csv_model.summary()

from numpy.core.multiarray import concatenate
#split train / validation sets
csv_features = csv_features.reshape(HOW_MANY_ROWS_FOR_EACH_GOOD_AND_BAD, HOW_MANY_DATA_POINTS_PER_ROW, 1)
x_train, x_val, y_train1, y_val1, y_train2, y_val2, y_train3, y_val3 = sklearn.model_selection.train_test_split(csv_features,csv_labels1,csv_labels2,csv_labels3,test_size=0.2)

'''
x_train1 = []
for i in range(len(x_train)):
  a = [[x] for x in np.asarray(range(len(x_train[i])))]
  b = [[x] for x in x_train[i]]
  c = np.concatenate([a,b], axis=1)
  x_train1.append(c)
x_val1 = []
for i in range(len(x_val)):
  a = [[x] for x in np.asarray(range(len(x_val[i])))]
  b = [[x] for x in x_val[i]]
  c = np.concatenate([a,b], axis=1)
  x_val1.append(c)
y_train_scc = []
for i in range(len(y_train1)):
  y_train_scc.append([y_train2[i]]) #, y_train3[i]])
y_val_scc = []
for i in range(len(y_val1)):
  y_val_scc.append([y_val2[i]]) #, y_val3[i]])

x_train1 = np.asarray(x_train1)
x_val1 = np.asarray(x_val1)
y_train_scc = np.asarray(y_train_scc).astype(int)
y_val_scc = np.asarray(y_val_scc).astype(int)

print(x_train1.shape)
print(x_val1.shape)
print(y_train_scc.shape)
print(y_val_scc.shape)
'''

print("Print a Graph")
print(y_val1[201], y_val2[201], y_val3[201])
plt.plot(x, x_val[201], '-')

print("Print another Graph")
print(y_val1[2], y_val2[2], y_val3[2])
plt.plot(x, x_val[2], '-')

print(x_train)

history = csv_model.fit(x_train, x_train, epochs=100, batch_size=100, validation_data=(x_val, x_val),
#history = csv_model.fit(x_train, [y_train1,y_train2,y_train3], epochs=100, batch_size=100,validation_data=(x_val, [y_val1,y_val2,y_val3]),
                    callbacks=[tf.keras.callbacks.EarlyStopping(monitor="val_loss", patience=5, mode="min")],
                    verbose=1)

#save and reload the model - uncomment following if you want to save the model and reload it
#MODEL_PATH = 'SavedModel.tf'
#csv_model.save(MODEL_PATH)
#reloaded_model = tf.keras.models.load_model(MODEL_PATH)

csv_model.evaluate(x_val, [y_val1,y_val2,y_val3])

history_dict = history.history
history_dict.keys()

loss = history.history['loss']
val_loss = history.history['val_loss']

epochs = range(1, len(loss) + 1)

# "bo" is for "blue dot"
plt.plot(epochs, loss, 'bo', label='Training loss')
# b is for "solid blue line"
plt.plot(epochs, val_loss, 'b', label='Validation loss')
plt.title('Training and validation loss')
plt.xlabel('Epochs')
plt.ylabel('Loss')
plt.legend()

plt.show()

def check_accuracy(verbose = False):
  good_graph = returnFakeRow()
  data = np.array([[x] for x in good_graph[0]])
  data = tf.reshape(data, [1000, 1])
  print(data.shape, data)
  predictions = csv_model([data])
  print(predictions)
  #print(predictions[0].numpy()[0][0])
  #print(predictions[1].numpy()[0][0])
  val1 = 0 #predictions[0].numpy()[0][0].astype(float)
  val2 = predictions[0].numpy()[0][0].astype(float)
  val3 = 0 #predictions[2].numpy()[0][0].astype(float)
  delta1 = np.abs(round(good_graph[1]-val1,3))
  delta2 = np.abs(round(good_graph[2]-val2,3))
  delta3 = np.abs(round(good_graph[3]-val3,3))
  if verbose:
    print("Model Wavelength: " + str(round(val1,3)) + " Ground Truth: " + str(round(good_graph[1],3)) + " Delta: " + str(delta1))
    print("Model Start: " + str(round(val2,3)) + " Ground Truth: " + str(round(good_graph[2],3)) + " Delta: " + str(delta2))
    print("Model Stop: " + str(round(val3,3)) + " Ground Truth: " + str(round(good_graph[3],3)) + " Delta: " + str(delta3))
    plt.plot(x, good_graph[0], '-')
    per1 = val2/10 + ((np.pi / np.degrees(val1/10)) / 2)
    plt.plot([per1,val2/10,val3/10], [45,45,45], "x")
  return good_graph[0],[val1,val2,val3],[delta1,delta2,delta3]

csv_model.summary()
_ = check_accuracy(True)

min_error = [100, 100, 100]
max_error = [0, 0, 0]
avg_error = [0, 0, 0]
best = [[],[],[]]
worst = [[],[],[]]
overall_best = [[],[],[1000,1000,1000]]
overall_worst = [[],[],[0,0,0]]
for i in range(100):
  data,vals,errors = check_accuracy()
  for j in range(len(errors)):
    if errors[j] < min_error[j]:
      min_error[j] = errors[j]
      best[j] = [data,vals,errors]
    if errors[j] > max_error[j]:
      max_error[j] = errors[j]
      worst[j] = [data,vals,errors]
    avg_error[j] = avg_error[j] + (errors[j] / 100)
    if np.sum(errors) < np.sum(overall_best[2]):
      overall_best = [data,vals,errors]
    if np.sum(errors) > np.sum(overall_worst[2]):
      overall_worst = [data,vals,errors]

j = 0
best = [overall_best]
plt.figure()
plt.title("Best: " + str(best[j][2]))
plt.plot(x, best[j][0], '-')
val1 = best[j][1][0]
val2 = best[j][1][1]/10
val3 = best[j][1][2]/10
per1 = val2 + ((np.pi / np.degrees(val1/10)) / 2)
plt.plot([per1,val2,val3], [45,45,45], "x")

best = [overall_worst]
plt.figure()
plt.title("Worst: " + str(best[j][2]))
plt.plot(x, best[j][0], '-')
val1 = best[j][1][0]
val2 = best[j][1][1]/10
val3 = best[j][1][2]/10
per1 = val2 + ((np.pi / np.degrees(val1/10)) / 2)
plt.plot([per1,val2,val3], [45,45,45], "x")

'''
for j in range(len(best)):
    plt.figure()
    plt.title("Best: " + str(best[j][2]))
    plt.plot(x, best[j][0], '-')
    val1 = best[j][1][0]
    val2 = best[j][1][1]
    val3 = best[j][1][2]
    per1 = val2 + ((np.pi / np.degrees(val1)) / 2)
    plt.plot([per1,val2,val3], [0,0,0], "x")

for j in range(len(worst)):
    plt.figure()
    plt.title("Worst: " + str(worst[j][2]))
    plt.plot(x, worst[j][0], '-')
    val1 = worst[j][1][0]
    val2 = worst[j][1][1]
    val3 = worst[j][1][2]
    per1 = val2 + ((np.pi / np.degrees(val1)) / 2)
    plt.plot([per1,val2,val3], [0,0,0], "x")
'''

print("min_error:", min_error)
print("avg_error:", np.round(avg_error, 3))
print("max_error:", max_error)